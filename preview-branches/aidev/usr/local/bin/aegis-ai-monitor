#!/usr/bin/env python3
"""
Aegis AI Monitor - AI workload monitoring interface
Features: Tensor core utilization, batch throughput, gradient analysis, VRAM monitoring

Provides GUI (GTK) and CLI modes with tier-based feature gating.
"""

import os
import sys
import json
import subprocess
import logging
import argparse
import shutil
import time
import threading
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from collections import deque
from datetime import datetime

TIER_LIMIT = "aidev"
VERSION = "1.5.0"
APP_NAME = "Aegis AI Monitor"

CONFIG_FILE = "/etc/aegis/aidev-config.json"
LOG_FILE = "/var/log/aegis/ai-monitor.log"

try:
    import gi
    gi.require_version('Gtk', '3.0')
    from gi.repository import Gtk, GLib
    GTK_AVAILABLE = True
except ImportError:
    GTK_AVAILABLE = False


class LicenseTier:
    FREEMIUM = 1
    BASIC = 2
    AIDEV = 4
    SERVER = 5


@dataclass
class GPUMetrics:
    device_id: int
    name: str
    temperature_c: int
    power_draw_w: float
    power_limit_w: float
    gpu_utilization: int
    memory_utilization: int
    memory_used_mb: int
    memory_total_mb: int
    sm_clock_mhz: int
    memory_clock_mhz: int
    timestamp: str


@dataclass
class TensorCoreMetrics:
    active: bool
    utilization_percent: float
    operations_per_second: float
    precision_mode: str


@dataclass
class TrainingMetrics:
    samples_per_second: float
    batches_per_second: float
    current_loss: float
    gradient_norm: float
    learning_rate: float
    epoch: int
    step: int


@dataclass
class VRAMFragmentation:
    total_mb: int
    used_mb: int
    free_mb: int
    largest_free_block_mb: int
    fragmentation_percent: float
    num_allocations: int


@dataclass
class DiskIOMetrics:
    read_mb_per_sec: float
    write_mb_per_sec: float
    read_iops: int
    write_iops: int
    io_wait_percent: float
    saturation_percent: float


class AegisAIMonitor:
    def __init__(self, headless: bool = False):
        self.headless = headless
        self.version = VERSION
        self.config = {}
        self.license_tier = LicenseTier.FREEMIUM
        self.monitoring = False
        self.monitor_thread = None
        self.metrics_history: deque = deque(maxlen=1000)
        self.callbacks: List[Callable] = []
        
        self.setup_logging()
        self.load_license_tier()
        self.load_config()
        
    def setup_logging(self):
        log_dir = Path(LOG_FILE).parent
        try:
            log_dir.mkdir(parents=True, exist_ok=True)
        except (PermissionError, OSError):
            pass
        
        try:
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - [%(name)s] %(message)s',
                handlers=[
                    logging.FileHandler(LOG_FILE) if os.access(str(log_dir), os.W_OK) else logging.NullHandler(),
                    logging.StreamHandler() if not self.headless else logging.NullHandler()
                ]
            )
        except Exception:
            logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler()])
        
        self.logger = logging.getLogger("AegisAIMonitor")
        self.logger.info(f"Starting {APP_NAME} v{VERSION}")
    
    def load_license_tier(self):
        license_file = Path("/etc/aegis/license.json")
        try:
            if license_file.exists():
                with open(license_file, 'r') as f:
                    license_data = json.load(f)
                edition = license_data.get('edition', 'freemium').lower()
                tier_map = {
                    'freemium': LicenseTier.FREEMIUM,
                    'basic': LicenseTier.BASIC,
                    'aidev': LicenseTier.AIDEV,
                    'server': LicenseTier.SERVER
                }
                self.license_tier = tier_map.get(edition, LicenseTier.FREEMIUM)
            else:
                if Path("/etc/aegis-aidev-marker").exists():
                    self.license_tier = LicenseTier.AIDEV
        except Exception as e:
            self.logger.warning(f"Failed to load license tier: {e}")
    
    def is_feature_available(self) -> bool:
        return self.license_tier >= LicenseTier.AIDEV
    
    def load_config(self):
        default_config = {
            "poll_interval_ms": 1000,
            "history_size": 1000,
            "alert_gpu_temp_c": 85,
            "alert_vram_percent": 95,
            "alert_gradient_threshold": 100,
            "log_metrics": True
        }
        
        try:
            if Path(CONFIG_FILE).exists():
                with open(CONFIG_FILE, 'r') as f:
                    file_config = json.load(f)
                    if "features" in file_config and "ai_monitor" in file_config["features"]:
                        self.config = {**default_config, **file_config["features"]["ai_monitor"]}
                    else:
                        self.config = default_config
            else:
                self.config = default_config
        except Exception as e:
            self.logger.error(f"Error loading config: {e}")
            self.config = default_config

    def get_gpu_metrics(self) -> List[GPUMetrics]:
        metrics = []
        
        if not shutil.which("nvidia-smi"):
            return metrics
        
        try:
            result = subprocess.run(
                ["nvidia-smi", 
                 "--query-gpu=index,name,temperature.gpu,power.draw,power.limit,"
                 "utilization.gpu,utilization.memory,memory.used,memory.total,"
                 "clocks.current.sm,clocks.current.memory",
                 "--format=csv,noheader,nounits"],
                capture_output=True, text=True, timeout=5
            )
            
            if result.returncode == 0:
                timestamp = datetime.now().isoformat()
                for line in result.stdout.strip().split('\n'):
                    if not line.strip():
                        continue
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 11:
                        try:
                            gpu = GPUMetrics(
                                device_id=int(parts[0]),
                                name=parts[1],
                                temperature_c=int(float(parts[2])) if parts[2] != '[N/A]' else 0,
                                power_draw_w=float(parts[3]) if parts[3] != '[N/A]' else 0,
                                power_limit_w=float(parts[4]) if parts[4] != '[N/A]' else 0,
                                gpu_utilization=int(parts[5]) if parts[5] != '[N/A]' else 0,
                                memory_utilization=int(parts[6]) if parts[6] != '[N/A]' else 0,
                                memory_used_mb=int(float(parts[7])) if parts[7] != '[N/A]' else 0,
                                memory_total_mb=int(float(parts[8])) if parts[8] != '[N/A]' else 0,
                                sm_clock_mhz=int(parts[9]) if parts[9] != '[N/A]' else 0,
                                memory_clock_mhz=int(parts[10]) if parts[10] != '[N/A]' else 0,
                                timestamp=timestamp
                            )
                            metrics.append(gpu)
                        except (ValueError, IndexError):
                            continue
        except Exception as e:
            self.logger.error(f"Error getting GPU metrics: {e}")
        
        return metrics

    def get_tensor_core_metrics(self, device_id: int = 0) -> TensorCoreMetrics:
        if not self.is_feature_available():
            return TensorCoreMetrics(
                active=False,
                utilization_percent=0,
                operations_per_second=0,
                precision_mode="disabled"
            )
        
        gpu_metrics = self.get_gpu_metrics()
        if not gpu_metrics:
            return TensorCoreMetrics(
                active=False,
                utilization_percent=0,
                operations_per_second=0,
                precision_mode="n/a"
            )
        
        gpu = next((g for g in gpu_metrics if g.device_id == device_id), gpu_metrics[0])
        
        has_tensor_cores = "A100" in gpu.name or "V100" in gpu.name or "RTX" in gpu.name or "H100" in gpu.name
        
        estimated_util = gpu.gpu_utilization * 0.7 if has_tensor_cores else 0
        estimated_tops = (gpu.sm_clock_mhz * 0.001 * 312) if has_tensor_cores else 0
        
        return TensorCoreMetrics(
            active=has_tensor_cores and gpu.gpu_utilization > 10,
            utilization_percent=estimated_util,
            operations_per_second=estimated_tops * 1e12,
            precision_mode="tf32" if has_tensor_cores else "fp32"
        )

    def analyze_gradient_stability(self, gradient_norms: List[float]) -> Dict[str, Any]:
        if not gradient_norms:
            return {
                "stable": True,
                "mean": 0,
                "std": 0,
                "max": 0,
                "min": 0,
                "explosion_detected": False,
                "vanishing_detected": False
            }
        
        mean_norm = sum(gradient_norms) / len(gradient_norms)
        variance = sum((x - mean_norm) ** 2 for x in gradient_norms) / len(gradient_norms)
        std_norm = variance ** 0.5
        max_norm = max(gradient_norms)
        min_norm = min(gradient_norms)
        
        explosion_threshold = self.config.get("alert_gradient_threshold", 100)
        explosion_detected = max_norm > explosion_threshold
        vanishing_detected = mean_norm < 1e-7
        
        return {
            "stable": not (explosion_detected or vanishing_detected),
            "mean": mean_norm,
            "std": std_norm,
            "max": max_norm,
            "min": min_norm,
            "explosion_detected": explosion_detected,
            "vanishing_detected": vanishing_detected
        }

    def get_vram_fragmentation(self, device_id: int = 0) -> VRAMFragmentation:
        gpu_metrics = self.get_gpu_metrics()
        if not gpu_metrics:
            return VRAMFragmentation(
                total_mb=0,
                used_mb=0,
                free_mb=0,
                largest_free_block_mb=0,
                fragmentation_percent=0,
                num_allocations=0
            )
        
        gpu = next((g for g in gpu_metrics if g.device_id == device_id), gpu_metrics[0])
        
        free_mb = gpu.memory_total_mb - gpu.memory_used_mb
        
        estimated_largest_block = free_mb * 0.85
        fragmentation = ((free_mb - estimated_largest_block) / free_mb * 100) if free_mb > 0 else 0
        
        estimated_allocations = max(1, gpu.memory_used_mb // 100)
        
        return VRAMFragmentation(
            total_mb=gpu.memory_total_mb,
            used_mb=gpu.memory_used_mb,
            free_mb=free_mb,
            largest_free_block_mb=int(estimated_largest_block),
            fragmentation_percent=fragmentation,
            num_allocations=estimated_allocations
        )

    def get_disk_io_metrics(self) -> DiskIOMetrics:
        metrics = DiskIOMetrics(
            read_mb_per_sec=0,
            write_mb_per_sec=0,
            read_iops=0,
            write_iops=0,
            io_wait_percent=0,
            saturation_percent=0
        )
        
        try:
            if Path("/proc/diskstats").exists():
                with open("/proc/diskstats", 'r') as f:
                    for line in f:
                        parts = line.split()
                        if len(parts) >= 14:
                            device = parts[2]
                            if device.startswith("sd") or device.startswith("nvme"):
                                read_sectors = int(parts[5])
                                write_sectors = int(parts[9])
                                
                                metrics.read_mb_per_sec = (read_sectors * 512) / (1024 * 1024)
                                metrics.write_mb_per_sec = (write_sectors * 512) / (1024 * 1024)
                                break
            
            if Path("/proc/stat").exists():
                with open("/proc/stat", 'r') as f:
                    for line in f:
                        if line.startswith("cpu "):
                            parts = line.split()
                            if len(parts) >= 6:
                                iowait = int(parts[5])
                                total = sum(int(p) for p in parts[1:8])
                                metrics.io_wait_percent = (iowait / total * 100) if total > 0 else 0
                            break
        except Exception as e:
            self.logger.error(f"Error getting disk I/O metrics: {e}")
        
        return metrics

    def check_memory_pressure(self, device_id: int = 0) -> Dict[str, Any]:
        gpu_metrics = self.get_gpu_metrics()
        if not gpu_metrics:
            return {"pressure": "unknown", "level": 0, "recommendations": []}
        
        gpu = next((g for g in gpu_metrics if g.device_id == device_id), gpu_metrics[0])
        
        vram_percent = (gpu.memory_used_mb / gpu.memory_total_mb * 100) if gpu.memory_total_mb > 0 else 0
        
        alert_threshold = self.config.get("alert_vram_percent", 95)
        
        if vram_percent >= alert_threshold:
            pressure = "critical"
            recommendations = [
                "Reduce batch size immediately",
                "Enable gradient checkpointing",
                "Use mixed precision training",
                "Clear unused tensors from memory"
            ]
        elif vram_percent >= 85:
            pressure = "high"
            recommendations = [
                "Consider reducing batch size",
                "Enable gradient accumulation",
                "Monitor for OOM errors"
            ]
        elif vram_percent >= 70:
            pressure = "moderate"
            recommendations = [
                "Memory usage is healthy",
                "You may be able to increase batch size"
            ]
        else:
            pressure = "low"
            recommendations = [
                "Consider increasing batch size for faster training",
                "Memory is underutilized"
            ]
        
        return {
            "pressure": pressure,
            "level": vram_percent,
            "used_mb": gpu.memory_used_mb,
            "total_mb": gpu.memory_total_mb,
            "recommendations": recommendations
        }

    def start_monitoring(self, callback: Optional[Callable] = None):
        if not self.is_feature_available():
            return {"success": False, "error": "Monitoring requires AI Developer edition"}
        
        if self.monitoring:
            return {"success": False, "error": "Already monitoring"}
        
        if callback:
            self.callbacks.append(callback)
        
        def monitor_loop():
            interval_sec = self.config.get("poll_interval_ms", 1000) / 1000
            while self.monitoring:
                gpu_metrics = self.get_gpu_metrics()
                if gpu_metrics:
                    self.metrics_history.append({
                        "timestamp": datetime.now().isoformat(),
                        "gpus": [asdict(g) for g in gpu_metrics]
                    })
                    
                    for cb in self.callbacks:
                        try:
                            cb(gpu_metrics)
                        except Exception as e:
                            self.logger.error(f"Callback error: {e}")
                
                time.sleep(interval_sec)
        
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        self.monitor_thread.start()
        
        return {"success": True, "status": "monitoring started"}

    def stop_monitoring(self):
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
            self.monitor_thread = None
        self.callbacks.clear()
        return {"success": True, "status": "monitoring stopped"}

    def get_status(self) -> Dict[str, Any]:
        gpu_metrics = self.get_gpu_metrics()
        
        return {
            "version": self.version,
            "license_tier": "aidev" if self.is_feature_available() else "limited",
            "monitoring": self.monitoring,
            "gpus": [asdict(g) for g in gpu_metrics],
            "history_size": len(self.metrics_history),
            "config": self.config
        }

    def run_gui(self):
        if not GTK_AVAILABLE:
            return self.run_cli()
        
        win = AIMonitorWindow(self)
        win.connect("destroy", Gtk.main_quit)
        win.show_all()
        Gtk.main()
    
    def run_cli(self):
        print(f"\n{'='*70}")
        print(f"  {APP_NAME} v{VERSION}")
        print(f"  License: {'AI Developer Edition' if self.is_feature_available() else 'LIMITED'}")
        print(f"{'='*70}\n")
        
        gpu_metrics = self.get_gpu_metrics()
        
        if gpu_metrics:
            for gpu in gpu_metrics:
                print(f"GPU {gpu.device_id}: {gpu.name}")
                print(f"  Temperature: {gpu.temperature_c}°C")
                print(f"  Power: {gpu.power_draw_w:.1f}W / {gpu.power_limit_w:.1f}W")
                print(f"  GPU Utilization: {gpu.gpu_utilization}%")
                print(f"  Memory: {gpu.memory_used_mb}MB / {gpu.memory_total_mb}MB ({gpu.memory_utilization}%)")
                print(f"  Clocks: SM {gpu.sm_clock_mhz}MHz, Memory {gpu.memory_clock_mhz}MHz")
                print()
                
                tensor = self.get_tensor_core_metrics(gpu.device_id)
                print(f"  Tensor Cores: {'Active' if tensor.active else 'Inactive'}")
                print(f"  Tensor Utilization: {tensor.utilization_percent:.1f}%")
                print(f"  Precision Mode: {tensor.precision_mode}")
                print()
                
                pressure = self.check_memory_pressure(gpu.device_id)
                print(f"  Memory Pressure: {pressure['pressure'].upper()} ({pressure['level']:.1f}%)")
                for rec in pressure['recommendations'][:2]:
                    print(f"    → {rec}")
                print()
        else:
            print("No GPU devices detected")
        
        disk_io = self.get_disk_io_metrics()
        print("Disk I/O:")
        print(f"  Read: {disk_io.read_mb_per_sec:.1f} MB/s")
        print(f"  Write: {disk_io.write_mb_per_sec:.1f} MB/s")
        print(f"  I/O Wait: {disk_io.io_wait_percent:.1f}%")


if GTK_AVAILABLE:
    class AIMonitorWindow(Gtk.Window):
        def __init__(self, app: AegisAIMonitor):
            super().__init__(title=f"{APP_NAME} v{VERSION}")
            self.app = app
            self.set_default_size(1000, 800)
            self.set_border_width(10)
            self.update_timer = None
            self.setup_ui()
            self.start_updates()
        
        def setup_ui(self):
            vbox = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
            self.add(vbox)
            
            header = Gtk.Label()
            header.set_markup(f"<big><b>{APP_NAME}</b></big>")
            vbox.pack_start(header, False, False, 10)
            
            notebook = Gtk.Notebook()
            vbox.pack_start(notebook, True, True, 0)
            
            notebook.append_page(self.create_overview_tab(), Gtk.Label(label="Overview"))
            notebook.append_page(self.create_tensor_tab(), Gtk.Label(label="Tensor Cores"))
            notebook.append_page(self.create_memory_tab(), Gtk.Label(label="VRAM"))
            notebook.append_page(self.create_io_tab(), Gtk.Label(label="Disk I/O"))
        
        def create_overview_tab(self):
            self.overview_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
            self.overview_box.set_margin_top(20)
            self.overview_box.set_margin_start(20)
            
            self.update_overview()
            return self.overview_box
        
        def create_tensor_tab(self):
            self.tensor_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
            self.tensor_box.set_margin_top(20)
            self.tensor_box.set_margin_start(20)
            
            self.update_tensor()
            return self.tensor_box
        
        def create_memory_tab(self):
            self.memory_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
            self.memory_box.set_margin_top(20)
            self.memory_box.set_margin_start(20)
            
            self.update_memory()
            return self.memory_box
        
        def create_io_tab(self):
            self.io_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
            self.io_box.set_margin_top(20)
            self.io_box.set_margin_start(20)
            
            self.update_io()
            return self.io_box
        
        def clear_box(self, box):
            for child in box.get_children():
                box.remove(child)
        
        def update_overview(self):
            self.clear_box(self.overview_box)
            
            gpu_metrics = self.app.get_gpu_metrics()
            
            for gpu in gpu_metrics:
                frame = Gtk.Frame(label=f"GPU {gpu.device_id}: {gpu.name}")
                frame_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=5)
                frame_box.set_margin_top(10)
                frame_box.set_margin_start(10)
                frame_box.set_margin_bottom(10)
                
                temp_bar = Gtk.ProgressBar()
                temp_bar.set_fraction(gpu.temperature_c / 100)
                temp_bar.set_text(f"Temperature: {gpu.temperature_c}°C")
                temp_bar.set_show_text(True)
                frame_box.pack_start(temp_bar, False, False, 5)
                
                gpu_bar = Gtk.ProgressBar()
                gpu_bar.set_fraction(gpu.gpu_utilization / 100)
                gpu_bar.set_text(f"GPU: {gpu.gpu_utilization}%")
                gpu_bar.set_show_text(True)
                frame_box.pack_start(gpu_bar, False, False, 5)
                
                mem_bar = Gtk.ProgressBar()
                mem_percent = gpu.memory_used_mb / gpu.memory_total_mb if gpu.memory_total_mb > 0 else 0
                mem_bar.set_fraction(mem_percent)
                mem_bar.set_text(f"Memory: {gpu.memory_used_mb}MB / {gpu.memory_total_mb}MB")
                mem_bar.set_show_text(True)
                frame_box.pack_start(mem_bar, False, False, 5)
                
                power_lbl = Gtk.Label(label=f"Power: {gpu.power_draw_w:.1f}W / {gpu.power_limit_w:.1f}W")
                power_lbl.set_xalign(0)
                frame_box.pack_start(power_lbl, False, False, 5)
                
                frame.add(frame_box)
                self.overview_box.pack_start(frame, False, False, 10)
            
            if not gpu_metrics:
                no_gpu = Gtk.Label(label="No GPU devices detected")
                self.overview_box.pack_start(no_gpu, False, False, 20)
            
            self.overview_box.show_all()
        
        def update_tensor(self):
            self.clear_box(self.tensor_box)
            
            gpu_metrics = self.app.get_gpu_metrics()
            
            for gpu in gpu_metrics:
                tensor = self.app.get_tensor_core_metrics(gpu.device_id)
                
                frame = Gtk.Frame(label=f"GPU {gpu.device_id} Tensor Cores")
                frame_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=5)
                frame_box.set_margin_top(10)
                frame_box.set_margin_start(10)
                frame_box.set_margin_bottom(10)
                
                status = "Active" if tensor.active else "Inactive"
                status_lbl = Gtk.Label(label=f"Status: {status}")
                status_lbl.set_xalign(0)
                frame_box.pack_start(status_lbl, False, False, 5)
                
                util_bar = Gtk.ProgressBar()
                util_bar.set_fraction(tensor.utilization_percent / 100)
                util_bar.set_text(f"Utilization: {tensor.utilization_percent:.1f}%")
                util_bar.set_show_text(True)
                frame_box.pack_start(util_bar, False, False, 5)
                
                prec_lbl = Gtk.Label(label=f"Precision Mode: {tensor.precision_mode}")
                prec_lbl.set_xalign(0)
                frame_box.pack_start(prec_lbl, False, False, 5)
                
                frame.add(frame_box)
                self.tensor_box.pack_start(frame, False, False, 10)
            
            self.tensor_box.show_all()
        
        def update_memory(self):
            self.clear_box(self.memory_box)
            
            gpu_metrics = self.app.get_gpu_metrics()
            
            for gpu in gpu_metrics:
                frag = self.app.get_vram_fragmentation(gpu.device_id)
                pressure = self.app.check_memory_pressure(gpu.device_id)
                
                frame = Gtk.Frame(label=f"GPU {gpu.device_id} VRAM")
                frame_box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=5)
                frame_box.set_margin_top(10)
                frame_box.set_margin_start(10)
                frame_box.set_margin_bottom(10)
                
                labels = [
                    f"Total: {frag.total_mb} MB",
                    f"Used: {frag.used_mb} MB",
                    f"Free: {frag.free_mb} MB",
                    f"Largest Free Block: {frag.largest_free_block_mb} MB",
                    f"Fragmentation: {frag.fragmentation_percent:.1f}%",
                    f"Pressure: {pressure['pressure'].upper()}"
                ]
                
                for text in labels:
                    lbl = Gtk.Label(label=text)
                    lbl.set_xalign(0)
                    frame_box.pack_start(lbl, False, False, 2)
                
                frame.add(frame_box)
                self.memory_box.pack_start(frame, False, False, 10)
            
            self.memory_box.show_all()
        
        def update_io(self):
            self.clear_box(self.io_box)
            
            io = self.app.get_disk_io_metrics()
            
            labels = [
                f"Read: {io.read_mb_per_sec:.1f} MB/s",
                f"Write: {io.write_mb_per_sec:.1f} MB/s",
                f"I/O Wait: {io.io_wait_percent:.1f}%"
            ]
            
            for text in labels:
                lbl = Gtk.Label(label=text)
                lbl.set_xalign(0)
                self.io_box.pack_start(lbl, False, False, 10)
            
            self.io_box.show_all()
        
        def start_updates(self):
            def update():
                if not self.get_property("visible"):
                    return False
                self.update_overview()
                self.update_tensor()
                self.update_memory()
                self.update_io()
                return True
            
            self.update_timer = GLib.timeout_add(2000, update)
        
        def do_destroy(self):
            if self.update_timer:
                GLib.source_remove(self.update_timer)
            Gtk.Window.do_destroy(self)


def main():
    parser = argparse.ArgumentParser(description=f"{APP_NAME}")
    parser.add_argument("--gui", action="store_true", help="Launch GUI mode")
    parser.add_argument("--cli", action="store_true", help="Run in CLI mode")
    parser.add_argument("--status", action="store_true", help="Show status")
    parser.add_argument("--gpu-metrics", action="store_true", help="Get GPU metrics")
    parser.add_argument("--tensor-metrics", type=int, metavar="DEVICE", nargs="?", const=0,
                       help="Get tensor core metrics for device")
    parser.add_argument("--vram-fragmentation", type=int, metavar="DEVICE", nargs="?", const=0,
                       help="Get VRAM fragmentation for device")
    parser.add_argument("--memory-pressure", type=int, metavar="DEVICE", nargs="?", const=0,
                       help="Check memory pressure for device")
    parser.add_argument("--disk-io", action="store_true", help="Get disk I/O metrics")
    parser.add_argument("--watch", action="store_true", help="Continuous monitoring mode")
    parser.add_argument("--interval", type=int, default=2, help="Watch interval in seconds")
    parser.add_argument("--json", action="store_true", help="Output as JSON")
    parser.add_argument("--version", action="version", version=f"{APP_NAME} {VERSION}")
    
    args = parser.parse_args()
    
    if args.status:
        logging.disable(logging.CRITICAL)
        for handler in logging.root.handlers[:]:
            logging.root.removeHandler(handler)
        logging.root.addHandler(logging.NullHandler())
        try:
            app = AegisAIMonitor(headless=True)
            gpu_metrics = app.get_gpu_metrics()
            gpu_list = []
            for gpu in gpu_metrics:
                gpu_list.append({
                    "device_id": gpu.device_id,
                    "name": gpu.name,
                    "temperature_c": gpu.temperature_c,
                    "gpu_utilization": gpu.gpu_utilization,
                    "memory_used_mb": gpu.memory_used_mb,
                    "memory_total_mb": gpu.memory_total_mb
                })
            alerts = []
            for gpu in gpu_metrics:
                if gpu.temperature_c > app.config.get("alert_gpu_temp_c", 85):
                    alerts.append({"type": "temperature", "device_id": gpu.device_id, "value": gpu.temperature_c})
                if gpu.memory_total_mb > 0:
                    vram_pct = (gpu.memory_used_mb / gpu.memory_total_mb) * 100
                    if vram_pct > app.config.get("alert_vram_percent", 95):
                        alerts.append({"type": "vram", "device_id": gpu.device_id, "value": vram_pct})
            status = {
                "available": True,
                "gpus": gpu_list,
                "alerts": alerts,
                "monitoring": app.monitoring,
                "version": VERSION
            }
            print(json.dumps(status))
            sys.exit(0)
        except Exception as e:
            print(json.dumps({"available": False, "error": str(e)}))
            sys.exit(1)
    elif args.gpu_metrics:
        app = AegisAIMonitor(headless=True)
        metrics = app.get_gpu_metrics()
        print(json.dumps([asdict(m) for m in metrics], indent=2))
    elif args.tensor_metrics is not None:
        app = AegisAIMonitor(headless=True)
        metrics = app.get_tensor_core_metrics(args.tensor_metrics)
        print(json.dumps(asdict(metrics), indent=2))
    elif args.vram_fragmentation is not None:
        app = AegisAIMonitor(headless=True)
        frag = app.get_vram_fragmentation(args.vram_fragmentation)
        print(json.dumps(asdict(frag), indent=2))
    elif args.memory_pressure is not None:
        app = AegisAIMonitor(headless=True)
        pressure = app.check_memory_pressure(args.memory_pressure)
        print(json.dumps(pressure, indent=2))
    elif args.disk_io:
        app = AegisAIMonitor(headless=True)
        io = app.get_disk_io_metrics()
        print(json.dumps(asdict(io), indent=2))
    elif args.watch:
        app = AegisAIMonitor(headless=True)
        try:
            while True:
                os.system('clear' if os.name == 'posix' else 'cls')
                app.run_cli()
                time.sleep(args.interval)
        except KeyboardInterrupt:
            print("\nMonitoring stopped")
    elif args.cli or not GTK_AVAILABLE:
        app = AegisAIMonitor(headless=False)
        app.run_cli()
    else:
        app = AegisAIMonitor(headless=False)
        app.run_gui()


if __name__ == "__main__":
    main()
