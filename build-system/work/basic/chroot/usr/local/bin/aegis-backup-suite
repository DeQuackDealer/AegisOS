#!/usr/bin/env python3
"""
Aegis Backup Suite - Comprehensive backup management for Basic edition
Features: Scheduled backups, restore points, incremental backups, cloud sync

Provides GUI (tkinter) and CLI modes with tier-based feature gating.
"""

import os
import sys
import json
import subprocess
import logging
import argparse
import threading
import time
import shutil
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict

TIER_LIMIT = "basic"
VERSION = "1.5.0"
APP_NAME = "Aegis Backup Suite"

CONFIG_FILE = "/etc/aegis/basic-config.json"
LOG_FILE = "/var/log/aegis/backup-suite.log"
DATA_DIR = "/var/lib/aegis/backup"

try:
    import gi
    gi.require_version('Gtk', '3.0')
    from gi.repository import Gtk, Gdk, GLib
    GTK_AVAILABLE = True
except ImportError:
    GTK_AVAILABLE = False


class LicenseTier:
    FREEMIUM = 1
    BASIC = 2
    GAMER = 3
    GAMER_AI = 4
    SERVER = 5


@dataclass
class BackupJob:
    name: str
    source_paths: List[str]
    destination: str
    schedule: str
    incremental: bool
    compression: str
    last_run: Optional[str]
    next_run: Optional[str]
    enabled: bool


@dataclass
class RestorePoint:
    id: str
    name: str
    timestamp: str
    size_bytes: int
    paths: List[str]
    backup_type: str


class AegisBackupSuite:
    def __init__(self, headless: bool = False):
        self.headless = headless
        self.version = VERSION
        self.config = {}
        self.license_tier = LicenseTier.FREEMIUM
        self.backup_jobs: List[BackupJob] = []
        self.restore_points: List[RestorePoint] = []
        
        self.setup_logging()
        self.load_license_tier()
        self.load_config()
        self.load_backup_jobs()
        
    def setup_logging(self):
        log_dir = Path(LOG_FILE).parent
        try:
            log_dir.mkdir(parents=True, exist_ok=True)
        except PermissionError:
            pass
        
        try:
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - [%(name)s] %(message)s',
                handlers=[
                    logging.FileHandler(LOG_FILE) if os.access(str(log_dir), os.W_OK) else logging.NullHandler(),
                    logging.StreamHandler() if not self.headless else logging.NullHandler()
                ]
            )
        except Exception:
            logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler()])
        
        self.logger = logging.getLogger("AegisBackupSuite")
        self.logger.info(f"Starting {APP_NAME} v{VERSION}")
    
    def load_license_tier(self):
        license_file = Path("/etc/aegis/license.json")
        try:
            if license_file.exists():
                with open(license_file, 'r') as f:
                    license_data = json.load(f)
                edition = license_data.get('edition', 'freemium').lower()
                tier_map = {
                    'freemium': LicenseTier.FREEMIUM,
                    'basic': LicenseTier.BASIC,
                    'gamer': LicenseTier.GAMER,
                    'gamer-ai': LicenseTier.GAMER_AI,
                    'server': LicenseTier.SERVER
                }
                self.license_tier = tier_map.get(edition, LicenseTier.FREEMIUM)
            else:
                markers = [
                    (Path("/etc/aegis-server-marker"), LicenseTier.SERVER),
                    (Path("/etc/aegis-basic-marker"), LicenseTier.BASIC),
                ]
                for marker, tier in markers:
                    if marker.exists():
                        self.license_tier = tier
                        break
        except Exception as e:
            self.logger.warning(f"Failed to load license tier: {e}")
    
    def is_feature_available(self, feature: str) -> bool:
        basic_features = ["scheduled_backup", "restore_points", "incremental", "compression"]
        server_features = ["cloud_sync", "disaster_recovery", "enterprise_backup"]
        
        if feature in basic_features:
            return self.license_tier >= LicenseTier.BASIC
        if feature in server_features:
            return self.license_tier >= LicenseTier.SERVER
        return False
    
    def load_config(self):
        default_config = {
            "backup_location": str(Path.home() / "Backups"),
            "max_restore_points": 5,
            "compression": "zstd",
            "incremental": True,
            "schedule": "weekly"
        }
        
        try:
            if Path(CONFIG_FILE).exists():
                with open(CONFIG_FILE, 'r') as f:
                    file_config = json.load(f)
                    if "features" in file_config and "backup_suite" in file_config["features"]:
                        self.config = {**default_config, **file_config["features"]["backup_suite"]}
                    else:
                        self.config = default_config
            else:
                self.config = default_config
        except Exception as e:
            self.logger.error(f"Error loading config: {e}")
            self.config = default_config
    
    def load_backup_jobs(self):
        jobs_file = Path(DATA_DIR) / "backup_jobs.json"
        try:
            if jobs_file.exists():
                with open(jobs_file, 'r') as f:
                    data = json.load(f)
                    self.backup_jobs = [BackupJob(**job) for job in data.get("jobs", [])]
        except Exception as e:
            self.logger.error(f"Error loading backup jobs: {e}")
    
    def save_backup_jobs(self):
        jobs_file = Path(DATA_DIR) / "backup_jobs.json"
        try:
            jobs_file.parent.mkdir(parents=True, exist_ok=True)
            data = {"jobs": [asdict(job) for job in self.backup_jobs]}
            with open(jobs_file, 'w') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            self.logger.error(f"Error saving backup jobs: {e}")
    
    def create_backup(self, name: str, sources: List[str], destination: str, 
                     incremental: bool = True, compression: str = "zstd") -> Dict[str, Any]:
        if not self.is_feature_available("scheduled_backup"):
            return {"success": False, "error": "Backup requires Basic edition or higher"}
        
        result = {
            "success": False,
            "backup_id": "",
            "size_bytes": 0,
            "files_backed_up": 0,
            "duration": 0
        }
        
        start_time = time.time()
        backup_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = Path(destination) / f"{name}_{backup_id}"
        
        try:
            backup_dir.mkdir(parents=True, exist_ok=True)
            
            total_files = 0
            total_size = 0
            
            for source in sources:
                source_path = Path(source).expanduser()
                if not source_path.exists():
                    self.logger.warning(f"Source path does not exist: {source}")
                    continue
                
                if source_path.is_file():
                    dest_file = backup_dir / source_path.name
                    shutil.copy2(source_path, dest_file)
                    total_files += 1
                    total_size += source_path.stat().st_size
                elif source_path.is_dir():
                    dest_dir = backup_dir / source_path.name
                    
                    if incremental and self.is_feature_available("incremental"):
                        for root, dirs, files in os.walk(source_path):
                            rel_root = Path(root).relative_to(source_path)
                            (dest_dir / rel_root).mkdir(parents=True, exist_ok=True)
                            for file in files:
                                src_file = Path(root) / file
                                dst_file = dest_dir / rel_root / file
                                shutil.copy2(src_file, dst_file)
                                total_files += 1
                                total_size += src_file.stat().st_size
                    else:
                        shutil.copytree(source_path, dest_dir)
                        for root, dirs, files in os.walk(dest_dir):
                            total_files += len(files)
                        total_size = sum(f.stat().st_size for f in dest_dir.rglob('*') if f.is_file())
            
            if compression != "none" and self.is_feature_available("compression"):
                archive_path = f"{backup_dir}.tar.{compression}"
                compress_cmd = {
                    "zstd": ["tar", "-I", "zstd", "-cvf", archive_path, "-C", str(backup_dir.parent), backup_dir.name],
                    "gzip": ["tar", "-czvf", f"{backup_dir}.tar.gz", "-C", str(backup_dir.parent), backup_dir.name],
                    "bzip2": ["tar", "-cjvf", f"{backup_dir}.tar.bz2", "-C", str(backup_dir.parent), backup_dir.name]
                }
                
                if compression in compress_cmd:
                    subprocess.run(compress_cmd[compression], capture_output=True)
                    shutil.rmtree(backup_dir)
                    archive = Path(archive_path if compression == "zstd" else f"{backup_dir}.tar.{compression}")
                    total_size = archive.stat().st_size if archive.exists() else total_size
            
            restore_point = RestorePoint(
                id=backup_id,
                name=name,
                timestamp=datetime.now().isoformat(),
                size_bytes=total_size,
                paths=sources,
                backup_type="incremental" if incremental else "full"
            )
            self.restore_points.append(restore_point)
            self._prune_restore_points()
            
            result["success"] = True
            result["backup_id"] = backup_id
            result["size_bytes"] = total_size
            result["files_backed_up"] = total_files
            result["duration"] = time.time() - start_time
            
            self.logger.info(f"Backup complete: {result}")
            
        except Exception as e:
            self.logger.error(f"Backup failed: {e}")
            result["error"] = str(e)
        
        return result
    
    def _prune_restore_points(self):
        max_points = self.config.get("max_restore_points", 5)
        if len(self.restore_points) > max_points:
            self.restore_points = sorted(self.restore_points, key=lambda x: x.timestamp, reverse=True)[:max_points]
    
    def list_restore_points(self) -> List[Dict[str, Any]]:
        return [asdict(rp) for rp in self.restore_points]
    
    def restore_from_point(self, restore_id: str, target_path: str) -> Dict[str, Any]:
        if not self.is_feature_available("restore_points"):
            return {"success": False, "error": "Restore points require Basic edition or higher"}
        
        for rp in self.restore_points:
            if rp.id == restore_id:
                backup_path = Path(self.config["backup_location"]) / f"{rp.name}_{rp.id}"
                
                if backup_path.exists():
                    target = Path(target_path)
                    target.mkdir(parents=True, exist_ok=True)
                    shutil.copytree(backup_path, target / backup_path.name, dirs_exist_ok=True)
                    return {"success": True, "restored_to": str(target)}
                
                for ext in [".tar.zstd", ".tar.gz", ".tar.bz2"]:
                    archive = Path(str(backup_path) + ext)
                    if archive.exists():
                        subprocess.run(["tar", "-xf", str(archive), "-C", target_path], capture_output=True)
                        return {"success": True, "restored_to": target_path}
        
        return {"success": False, "error": f"Restore point {restore_id} not found"}
    
    def run_scheduled_backup(self):
        if not self.is_feature_available("scheduled_backup"):
            return
        
        for job in self.backup_jobs:
            if job.enabled:
                self.logger.info(f"Running scheduled backup: {job.name}")
                self.create_backup(
                    name=job.name,
                    sources=job.source_paths,
                    destination=job.destination,
                    incremental=job.incremental,
                    compression=job.compression
                )
                job.last_run = datetime.now().isoformat()
        
        self.save_backup_jobs()
    
    def run_gui(self):
        if not GTK_AVAILABLE:
            print("GTK not available. Use --cli mode.")
            return self.run_cli()
        
        win = BackupSuiteWindow(self)
        win.connect("destroy", Gtk.main_quit)
        win.show_all()
        Gtk.main()
    
    def run_cli(self):
        print(f"\n{'='*60}")
        print(f"  {APP_NAME} v{VERSION}")
        print(f"  License Tier: {'BASIC+' if self.license_tier >= LicenseTier.BASIC else 'FREEMIUM (Limited)'}")
        print(f"{'='*60}\n")
        
        print("Backup Configuration:")
        print(f"  Location: {self.config.get('backup_location', 'Not set')}")
        print(f"  Compression: {self.config.get('compression', 'zstd')}")
        print(f"  Incremental: {self.config.get('incremental', True)}")
        print(f"  Max Restore Points: {self.config.get('max_restore_points', 5)}")
        
        print(f"\nBackup Jobs: {len(self.backup_jobs)}")
        print(f"Restore Points: {len(self.restore_points)}")
        
        if self.license_tier < LicenseTier.BASIC:
            print("\n⚠ Upgrade to Basic edition for backup features")
            print("  Visit: https://aegis-os.com/pricing")


if GTK_AVAILABLE:
    class BackupSuiteWindow(Gtk.Window):
        def __init__(self, app: AegisBackupSuite):
            super().__init__(title=f"{APP_NAME} v{VERSION}")
            self.app = app
            self.set_default_size(800, 600)
            self.set_border_width(10)
            self.setup_ui()
        
        def setup_ui(self):
            vbox = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
            self.add(vbox)
            
            header = Gtk.Label()
            header.set_markup(f"<big><b>{APP_NAME}</b></big>")
            vbox.pack_start(header, False, False, 10)
            
            if self.app.license_tier < LicenseTier.BASIC:
                warning = Gtk.Label()
                warning.set_markup("<span foreground='orange'>⚠ Limited features - Upgrade to Basic for full access</span>")
                vbox.pack_start(warning, False, False, 5)
            
            notebook = Gtk.Notebook()
            vbox.pack_start(notebook, True, True, 0)
            
            notebook.append_page(self.create_backup_tab(), Gtk.Label(label="Backup"))
            notebook.append_page(self.create_restore_tab(), Gtk.Label(label="Restore"))
            notebook.append_page(self.create_schedule_tab(), Gtk.Label(label="Schedule"))
        
        def create_backup_tab(self):
            box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
            box.set_margin_top(20)
            box.set_margin_start(20)
            
            backup_btn = Gtk.Button(label="Create Backup Now")
            backup_btn.connect("clicked", self.on_backup_clicked)
            backup_btn.set_sensitive(self.app.license_tier >= LicenseTier.BASIC)
            box.pack_start(backup_btn, False, False, 10)
            
            self.backup_status = Gtk.Label(label="Ready to backup")
            box.pack_start(self.backup_status, False, False, 5)
            
            return box
        
        def create_restore_tab(self):
            box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
            box.set_margin_top(20)
            box.set_margin_start(20)
            
            points = self.app.list_restore_points()
            if points:
                for point in points:
                    label = Gtk.Label(label=f"{point['name']} - {point['timestamp']}")
                    box.pack_start(label, False, False, 5)
            else:
                box.pack_start(Gtk.Label(label="No restore points available"), False, False, 5)
            
            return box
        
        def create_schedule_tab(self):
            box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)
            box.set_margin_top(20)
            box.set_margin_start(20)
            
            schedule_info = Gtk.Label(label=f"Current schedule: {self.app.config.get('schedule', 'weekly')}")
            box.pack_start(schedule_info, False, False, 10)
            
            return box
        
        def on_backup_clicked(self, button):
            self.backup_status.set_text("Backing up...")
            threading.Thread(target=self._run_backup, daemon=True).start()
        
        def _run_backup(self):
            result = self.app.create_backup(
                name="manual_backup",
                sources=[str(Path.home() / "Documents")],
                destination=self.app.config.get("backup_location", str(Path.home() / "Backups"))
            )
            GLib.idle_add(self._update_status, result)
        
        def _update_status(self, result):
            if result["success"]:
                self.backup_status.set_text(f"Backup complete: {result['files_backed_up']} files")
            else:
                self.backup_status.set_text(f"Backup failed: {result.get('error', 'Unknown error')}")


def main():
    parser = argparse.ArgumentParser(description=f"{APP_NAME} - Backup management tool")
    parser.add_argument("--gui", action="store_true", help="Launch GUI mode")
    parser.add_argument("--cli", action="store_true", help="Run in CLI mode")
    parser.add_argument("--scheduled", action="store_true", help="Run scheduled backups")
    parser.add_argument("--backup", metavar="NAME", help="Create backup with name")
    parser.add_argument("--source", metavar="PATH", action="append", help="Source path to backup")
    parser.add_argument("--dest", metavar="PATH", help="Destination path")
    parser.add_argument("--list-restore-points", action="store_true", help="List restore points")
    parser.add_argument("--version", action="version", version=f"{APP_NAME} {VERSION}")
    
    args = parser.parse_args()
    
    if args.scheduled:
        app = AegisBackupSuite(headless=True)
        app.run_scheduled_backup()
    elif args.backup:
        app = AegisBackupSuite(headless=True)
        sources = args.source or [str(Path.home() / "Documents")]
        dest = args.dest or app.config.get("backup_location", str(Path.home() / "Backups"))
        result = app.create_backup(args.backup, sources, dest)
        print(json.dumps(result, indent=2))
    elif args.list_restore_points:
        app = AegisBackupSuite(headless=True)
        points = app.list_restore_points()
        print(json.dumps(points, indent=2))
    elif args.cli or not GTK_AVAILABLE:
        app = AegisBackupSuite(headless=False)
        app.run_cli()
    else:
        app = AegisBackupSuite(headless=False)
        app.run_gui()


if __name__ == "__main__":
    main()
